#!/usr/bin/env python3
"""
KODOWANIE KORPUSU - SENTENCE-BERT
===================================
Generuje embeddingi dla ca≈Çego korpusu u≈ºywajƒÖc modeli Sentence-BERT.

Obs≈Çuguje r√≥≈ºne modele, w tym:
- intfloat/multilingual-e5-small (uniwersalny multilingual)
- sdadas/stella-pl (najlepszy dla polskiego - NDCG@10: 60.52)
- radlab/polish-sts-v2 (polski model podobie≈Ñstwa zda≈Ñ)

Zapisuje:
- Macierz embedding√≥w: sbert_<model_name>_embeddings.npy
- Mapƒô zda≈Ñ: sbert_sentence_map.json
"""

import numpy as np
import json
import logging
import os
import time
from sentence_transformers import SentenceTransformer
from corpora import CORPORA_FILES

# Ustawienie logowania
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

# --- KONFIGURACJA ---
# Wybierz model (odkomentuj jeden):
# MODEL_NAME = 'intfloat/multilingual-e5-small'  # Uniwersalny multilingual
MODEL_NAME = 'sdadas/stella-pl'  # ‚≠ê Najlepszy dla polskiego
# MODEL_NAME = 'radlab/polish-sts-v2'  # Polski model STS

files = CORPORA_FILES["ALL"]

# Automatyczne generowanie nazwy pliku wyj≈õciowego na podstawie modelu
model_slug = MODEL_NAME.replace('/', '_').replace('-', '_')
OUTPUT_EMBEDDINGS_FILE = f"sbert_{model_slug}_embeddings.npy"
OUTPUT_SENTENCE_MAP = "sbert_sentence_map.json"

print("\n" + "="*80)
print("  KODOWANIE KORPUSU - SENTENCE-BERT")
print("="*80)
print(f"Model: {MODEL_NAME}")
print("="*80)

# --- ETAP 1: Wczytanie Korpusu ---
def load_raw_sentences(file_list):
    """Wczytuje surowe zdania z listy plik√≥w."""
    raw_sentences = []
    print(f"\n[1/3] Wczytywanie tekstu z {len(file_list)} plik√≥w...")
    for file in file_list:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                lines = [line.strip() for line in f if line.strip()]
                raw_sentences.extend(lines)
        except FileNotFoundError:
            print(f"OSTRZE≈ªENIE: Nie znaleziono pliku '{file}'. Pomijam.")
        except Exception as e:
            print(f"B≈ÅƒÑD podczas przetwarzania pliku '{file}': {e}")

    if not raw_sentences:
        raise ValueError("Korpus danych jest pusty lub nie zosta≈Ç wczytany.")

    return raw_sentences

try:
    raw_sentences = load_raw_sentences(files)
    print(f"‚úì Wczytano {len(raw_sentences):,} zda≈Ñ do przetworzenia")
except ValueError as e:
    print(f"‚ùå B≈ÅƒÑD: {e}")
    exit(1)

# --- ETAP 2: ≈Åadowanie Modelu ---
print(f"\n[2/3] ≈Åadowanie modelu Sentence-BERT: {MODEL_NAME}...")
try:
    model_sbert = SentenceTransformer(MODEL_NAME)
    print("‚úì Model za≈Çadowany pomy≈õlnie")
    print(f"  ‚îî‚îÄ Wymiar embeddingu: {model_sbert.get_sentence_embedding_dimension()}")
except Exception as e:
    print(f"‚ùå FATALNY B≈ÅƒÑD podczas ≈Çadowania modelu {MODEL_NAME}: {e}")
    exit(1)

# --- ETAP 3: Generowanie Embedding√≥w ---
print(f"\n[3/3] Generowanie embedding√≥w dla {len(raw_sentences):,} zda≈Ñ...")
print("(To mo≈ºe potrwaƒá kilka minut...)")

start_time = time.time()

# Metoda .encode() automatycznie tokenizuje i generuje wektory
sentence_embeddings = model_sbert.encode(
    raw_sentences,
    show_progress_bar=True,
    convert_to_numpy=True,
    batch_size=32  # Mo≈ºesz zwiƒôkszyƒá je≈õli masz wiƒôcej RAM/GPU
)

end_time = time.time()
encoding_time = end_time - start_time

print(f"\n‚úì Generowanie zako≈Ñczone w {encoding_time:.2f}s")
print(f"  ‚îî‚îÄ Kszta≈Çt macierzy embedding√≥w: {sentence_embeddings.shape}")

# --- ETAP 4: Zapisywanie ---
print(f"\nüíæ Zapisywanie embedding√≥w...")

# Zapisz embeddingi
np.save(OUTPUT_EMBEDDINGS_FILE, sentence_embeddings)
emb_size_mb = os.path.getsize(OUTPUT_EMBEDDINGS_FILE) / (1024 * 1024)
print(f"‚úì Embeddingi zapisane: {OUTPUT_EMBEDDINGS_FILE} ({emb_size_mb:.1f} MB)")

# Zapisz mapƒô zda≈Ñ (je≈õli nie istnieje)
if not os.path.exists(OUTPUT_SENTENCE_MAP):
    with open(OUTPUT_SENTENCE_MAP, "w", encoding="utf-8") as f:
        json.dump(raw_sentences, f, ensure_ascii=False, indent=2)
    print(f"‚úì Mapa zda≈Ñ zapisana: {OUTPUT_SENTENCE_MAP}")
else:
    print(f"‚ÑπÔ∏è  Mapa zda≈Ñ ju≈º istnieje: {OUTPUT_SENTENCE_MAP}")

print("\n" + "="*80)
print("  KODOWANIE KORPUSU ZAKO≈ÉCZONE")
print("="*80)
print(f"\nüìä Podsumowanie:")
print(f"  ‚îú‚îÄ Model: {MODEL_NAME}")
print(f"  ‚îú‚îÄ Liczba zda≈Ñ: {len(raw_sentences):,}")
print(f"  ‚îú‚îÄ Wymiar wektora: {sentence_embeddings.shape[1]}")
print(f"  ‚îú‚îÄ Czas kodowania: {encoding_time:.2f}s")
print(f"  ‚îî‚îÄ Plik wyj≈õciowy: {OUTPUT_EMBEDDINGS_FILE}")
print(f"\nüí° Aby odpytaƒá korpus, uruchom:")
print(f"  python query-sbert.py")
print(f"\nüí° WA≈ªNE: W query-sbert.py u≈ºyj tego samego modelu: {MODEL_NAME}")
