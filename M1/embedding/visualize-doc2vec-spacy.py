#!/usr/bin/env python3
"""
Interaktywny skrypt do wizualizacji wynik√≥w modelu Doc2Vec z tokenizacjƒÖ spaCy.
Pozwala na:
- Wprowadzanie w≈Çasnych zda≈Ñ i znajdowanie podobnych
- PrzeglƒÖdanie losowych przyk≈Çad√≥w z korpusu
- Wizualizacjƒô embedding√≥w (t-SNE, PCA)
- Analizƒô statystyk modelu
"""

import numpy as np
import json
import logging
from gensim.models.doc2vec import Doc2Vec
import spacy
import sys
import random
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Wy≈ÇƒÖcz verbose logging
logging.basicConfig(level=logging.ERROR)

# Kolory ANSI dla terminala
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

def print_header(text, width=80):
    """Wy≈õwietla nag≈Ç√≥wek z kolorami."""
    print("\n" + Colors.BOLD + Colors.CYAN + "="*width + Colors.ENDC)
    print(Colors.BOLD + Colors.CYAN + text.center(width) + Colors.ENDC)
    print(Colors.BOLD + Colors.CYAN + "="*width + Colors.ENDC)

def print_subheader(text):
    """Wy≈õwietla podtytu≈Ç."""
    print("\n" + Colors.BOLD + Colors.BLUE + text + Colors.ENDC)
    print(Colors.BLUE + "-"*80 + Colors.ENDC)

def print_error(text):
    """Wy≈õwietla komunikat b≈Çƒôdu."""
    print(f"{Colors.RED}‚úó {text}{Colors.ENDC}")

def print_success(text):
    """Wy≈õwietla komunikat sukcesu."""
    print(f"{Colors.GREEN}‚úì {text}{Colors.ENDC}")

def print_info(text):
    """Wy≈õwietla informacjƒô."""
    print(f"{Colors.YELLOW}‚Ñπ {text}{Colors.ENDC}")

# Pliki modelu
MODEL_FILE = "doc2vec_model_spacy.model"
SENTENCE_MAP_FILE = "doc2vec_model_sentence_map_spacy.json"

print_header("WIZUALIZACJA DOC2VEC - MODEL SPACY")

# --- Wczytanie modelu i danych ---
print("\nWczytywanie modelu i danych...")

try:
    model = Doc2Vec.load(MODEL_FILE)
    print_success(f"Model za≈Çadowany: {MODEL_FILE}")
except FileNotFoundError:
    print_error(f"Nie znaleziono modelu: {MODEL_FILE}")
    print_info("Uruchom najpierw: python train-doc2vec-spacy.py")
    sys.exit(1)

try:
    with open(SENTENCE_MAP_FILE, "r", encoding="utf-8") as f:
        sentence_map = json.load(f)
    print_success(f"Mapa zda≈Ñ za≈Çadowana: {len(sentence_map):,} zda≈Ñ")
except FileNotFoundError:
    print_error(f"Nie znaleziono mapy zda≈Ñ: {SENTENCE_MAP_FILE}")
    sys.exit(1)

# Wczytanie modelu spaCy
try:
    nlp = spacy.load("pl_core_news_sm")
    print_success("Model spaCy za≈Çadowany: pl_core_news_sm")
except OSError:
    print_error("Nie znaleziono modelu spaCy")
    print_info("Zainstaluj: python -m spacy download pl_core_news_sm")
    sys.exit(1)

# --- Funkcje pomocnicze ---

def tokenize_spacy(text):
    """Tokenizacja z lemmatyzacjƒÖ (tak samo jak w treningu)."""
    doc = nlp(text)
    tokens = [
        token.lemma_.lower()
        for token in doc
        if not token.is_punct and not token.is_space and token.text.strip()
    ]
    return tokens

def find_similar(query_text, topn=10):
    """Znajduje podobne zdania do zapytania."""
    # Tokenizacja
    tokens = tokenize_spacy(query_text)

    if not tokens:
        print_error("Brak token√≥w po lemmatyzacji")
        return []

    # Wnioskowanie wektora
    vector = model.infer_vector(tokens, epochs=model.epochs)

    # Znajd≈∫ podobne
    similar = model.dv.most_similar([vector], topn=topn)

    return tokens, vector, similar

def display_similar_results(query_text, tokens, similar):
    """Wy≈õwietla wyniki wyszukiwania podobnych zda≈Ñ."""
    print_subheader(f'WYNIKI DLA: "{query_text}"')

    print(f"\n{Colors.BOLD}Tokeny (lemmatyzowane):{Colors.ENDC}")
    print(f"  {tokens}")
    print(f"  Liczba token√≥w: {len(tokens)}")

    print(f"\n{Colors.BOLD}Top {len(similar)} najbardziej podobnych zda≈Ñ:{Colors.ENDC}")
    for rank, (doc_id, similarity) in enumerate(similar, 1):
        sentence = sentence_map[int(doc_id)]
        # Pod≈õwietl wysokie podobie≈Ñstwa
        if similarity > 0.8:
            color = Colors.GREEN
        elif similarity > 0.6:
            color = Colors.YELLOW
        else:
            color = ""

        print(f"  {color}{rank:2d}. [{similarity:.4f}] {sentence[:100]}{Colors.ENDC}")
        if len(sentence) > 100:
            print(f"      {sentence[100:200]}...")

# --- Funkcje menu ---

def interactive_search():
    """Tryb interaktywnego wyszukiwania."""
    print_header("TRYB INTERAKTYWNY - Wyszukiwanie Podobnych Zda≈Ñ")
    print(f"\n{Colors.BOLD}Wprowad≈∫ w≈Çasne zdania aby znale≈∫ƒá podobne.{Colors.ENDC}")
    print(f"{Colors.YELLOW}Wpisz 'q' lub 'quit' aby zako≈Ñczyƒá.{Colors.ENDC}\n")

    while True:
        try:
            user_input = input(f"{Colors.BOLD}{Colors.GREEN}Zdanie > {Colors.ENDC}").strip()

            if user_input.lower() in ['q', 'quit', 'exit']:
                print(f"\n{Colors.YELLOW}Zamykam tryb interaktywny.{Colors.ENDC}")
                break

            if not user_input:
                print_info("Zdanie nie mo≈ºe byƒá puste.")
                continue

            # Znajd≈∫ podobne
            tokens, vector, similar = find_similar(user_input, topn=10)

            # Wy≈õwietl wyniki
            display_similar_results(user_input, tokens, similar)

            # Statystyki wektora
            print(f"\n{Colors.BOLD}Statystyki wektora:{Colors.ENDC}")
            print(f"  Norma L2: {np.linalg.norm(vector):.4f}")
            print(f"  ≈örednia warto≈õƒá: {np.mean(vector):.4f}")
            print(f"  Odchylenie std: {np.std(vector):.4f}")
            print()

        except EOFError:
            print(f"\n{Colors.YELLOW}Zako≈Ñczono.{Colors.ENDC}")
            break
        except KeyboardInterrupt:
            print(f"\n\n{Colors.YELLOW}Przerwano przez u≈ºytkownika.{Colors.ENDC}")
            break

def random_examples():
    """Pokazuje losowe przyk≈Çady z korpusu."""
    print_header("LOSOWE PRZYK≈ÅADY Z KORPUSU")

    num_examples = 5
    print(f"\nWylosujƒô {num_examples} zda≈Ñ i znajdƒô dla nich najbardziej podobne...\n")

    indices = random.sample(range(len(sentence_map)), num_examples)

    for i, idx in enumerate(indices, 1):
        sentence = sentence_map[idx]
        print(f"\n{Colors.BOLD}{Colors.YELLOW}‚ïê‚ïê‚ïê Przyk≈Çad {i}/{num_examples} ‚ïê‚ïê‚ïê{Colors.ENDC}")
        print(f"{Colors.BOLD}Zdanie ≈∫r√≥d≈Çowe:{Colors.ENDC}")
        print(f"  [{idx}] {sentence}")

        # Pobierz wektor dla tego dokumentu
        vector = model.dv[str(idx)]

        # Znajd≈∫ podobne (pomijajƒÖc siebie)
        similar = model.dv.most_similar([vector], topn=6)
        similar = [(doc_id, sim) for doc_id, sim in similar if int(doc_id) != idx][:5]

        print(f"\n{Colors.BOLD}Top 5 podobnych:{Colors.ENDC}")
        for rank, (doc_id, similarity) in enumerate(similar, 1):
            sent = sentence_map[int(doc_id)]
            print(f"  {rank}. [{similarity:.4f}] {sent[:80]}")

        if i < num_examples:
            input(f"\n{Colors.CYAN}Naci≈õnij Enter aby kontynuowaƒá...{Colors.ENDC}")

def visualize_embeddings():
    """Wizualizacja embedding√≥w u≈ºywajƒÖc t-SNE lub PCA."""
    print_header("WIZUALIZACJA EMBEDDING√ìW")

    print(f"\n{Colors.BOLD}Wybierz metodƒô wizualizacji:{Colors.ENDC}")
    print(f"  {Colors.CYAN}1.{Colors.ENDC} t-SNE (wolniejsze, lepsze dla struktur nieliniowych)")
    print(f"  {Colors.CYAN}2.{Colors.ENDC} PCA (szybsze, linearne)")
    print(f"  {Colors.CYAN}q.{Colors.ENDC} Powr√≥t do menu")

    choice = input(f"\n{Colors.BOLD}{Colors.GREEN}Wyb√≥r > {Colors.ENDC}").strip()

    if choice == 'q':
        return

    # Parametry wizualizacji
    num_samples = min(1000, len(sentence_map))  # Max 1000 punkt√≥w dla czytelno≈õci
    print(f"\n{Colors.YELLOW}Pr√≥bujƒô {num_samples} losowych dokument√≥w...{Colors.ENDC}")

    # Wylosuj indeksy
    indices = random.sample(range(len(sentence_map)), num_samples)

    # Pobierz wektory
    vectors = np.array([model.dv[str(i)] for i in indices])

    print(f"Rozmiar macierzy wektor√≥w: {vectors.shape}")

    # Redukuj wymiarowo≈õƒá
    if choice == '1':
        print(f"{Colors.YELLOW}Obliczam t-SNE (mo≈ºe potrwaƒá ~30s)...{Colors.ENDC}")
        reducer = TSNE(n_components=2, random_state=42, perplexity=30)
    else:
        print(f"{Colors.YELLOW}Obliczam PCA...{Colors.ENDC}")
        reducer = PCA(n_components=2, random_state=42)

    coords_2d = reducer.fit_transform(vectors)

    print_success("Redukcja wymiarowo≈õci zako≈Ñczona")

    # Wizualizacja
    print(f"{Colors.YELLOW}Tworzƒô wykres...{Colors.ENDC}")

    plt.figure(figsize=(12, 8))
    plt.scatter(coords_2d[:, 0], coords_2d[:, 1], alpha=0.5, s=10)

    method_name = "t-SNE" if choice == '1' else "PCA"
    plt.title(f"Wizualizacja {num_samples} embedding√≥w Doc2Vec (spaCy) - {method_name}", fontsize=14, fontweight='bold')
    plt.xlabel(f"{method_name} Dimension 1")
    plt.ylabel(f"{method_name} Dimension 2")
    plt.grid(True, alpha=0.3)

    # Opcjonalnie: zaznacz kilka losowych punkt√≥w z etykietami
    num_labels = min(20, num_samples // 50)
    labeled_indices = random.sample(range(num_samples), num_labels)

    for i in labeled_indices:
        idx = indices[i]
        sentence = sentence_map[idx][:30] + "..."
        plt.annotate(sentence,
                    xy=(coords_2d[i, 0], coords_2d[i, 1]),
                    xytext=(5, 5), textcoords='offset points',
                    fontsize=7, alpha=0.7,
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))

    plt.tight_layout()

    # Zapisz i poka≈º
    output_file = f"doc2vec_spacy_visualization_{method_name.lower()}.png"
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print_success(f"Wykres zapisany: {output_file}")

    print(f"\n{Colors.YELLOW}Czy otworzyƒá wykres? (t/n): {Colors.ENDC}", end="")
    show = input().strip().lower()

    if show in ['t', 'y', 'yes', 'tak']:
        plt.show()
    else:
        plt.close()

def show_statistics():
    """Wy≈õwietla statystyki modelu."""
    print_header("STATYSTYKI MODELU")

    print(f"\n{Colors.BOLD}{Colors.BLUE}üìä Parametry modelu:{Colors.ENDC}")
    print(f"  ‚îú‚îÄ Rozmiar s≈Çownika: {len(model.wv):,} unikalnych token√≥w")
    print(f"  ‚îú‚îÄ Wymiar wektora: {model.vector_size}")
    print(f"  ‚îú‚îÄ Liczba dokument√≥w: {len(model.dv):,}")
    print(f"  ‚îú‚îÄ Liczba epok treningu: {model.epochs}")
    print(f"  ‚îú‚îÄ Rozmiar okna: {model.window}")
    print(f"  ‚îú‚îÄ Minimalna liczno≈õƒá: {model.min_count}")
    print(f"  ‚îî‚îÄ Algorytm: PV-DBOW (dm=0)")

    # Analiza wektor√≥w
    print(f"\n{Colors.BOLD}{Colors.BLUE}üìà Analiza wektor√≥w dokument√≥w:{Colors.ENDC}")

    # Pobierz pr√≥bkƒô wektor√≥w
    sample_size = min(1000, len(model.dv))
    sample_indices = random.sample(range(len(model.dv)), sample_size)
    sample_vectors = np.array([model.dv[str(i)] for i in sample_indices])

    norms = np.linalg.norm(sample_vectors, axis=1)
    means = np.mean(sample_vectors, axis=1)
    stds = np.std(sample_vectors, axis=1)

    print(f"  (Analiza na pr√≥bce {sample_size} wektor√≥w)")
    print(f"  ‚îú‚îÄ ≈örednia norma L2: {np.mean(norms):.4f} ¬± {np.std(norms):.4f}")
    print(f"  ‚îú‚îÄ Min/Max norma: {np.min(norms):.4f} / {np.max(norms):.4f}")
    print(f"  ‚îú‚îÄ ≈örednia warto≈õƒá: {np.mean(means):.6f}")
    print(f"  ‚îî‚îÄ ≈örednie odchylenie std: {np.mean(stds):.4f}")

    # Top s≈Çowa w s≈Çowniku
    print(f"\n{Colors.BOLD}{Colors.BLUE}üìù Statystyki s≈Çownika:{Colors.ENDC}")

    # Sortuj s≈Çowa wed≈Çug czƒôsto≈õci (frequency)
    vocab_items = [(word, model.wv.get_vecattr(word, 'count'))
                   for word in list(model.wv.index_to_key)[:100]]
    vocab_items.sort(key=lambda x: x[1], reverse=True)

    print(f"\n  Top 20 najczƒôstszych token√≥w:")
    for i, (word, count) in enumerate(vocab_items[:20], 1):
        print(f"    {i:2d}. '{word}' ({count:,} wystƒÖpie≈Ñ)")

    # D≈Çugo≈õci zda≈Ñ
    print(f"\n{Colors.BOLD}{Colors.BLUE}üìè Statystyki korpusu:{Colors.ENDC}")
    sentence_lengths = [len(sent.split()) for sent in sentence_map]
    print(f"  ‚îú‚îÄ Liczba zda≈Ñ: {len(sentence_map):,}")
    print(f"  ‚îú‚îÄ ≈örednia d≈Çugo≈õƒá zdania: {np.mean(sentence_lengths):.1f} s≈Ç√≥w")
    print(f"  ‚îú‚îÄ Min/Max d≈Çugo≈õƒá: {np.min(sentence_lengths)} / {np.max(sentence_lengths)} s≈Ç√≥w")
    print(f"  ‚îî‚îÄ Mediana d≈Çugo≈õci: {np.median(sentence_lengths):.1f} s≈Ç√≥w")

    input(f"\n{Colors.CYAN}Naci≈õnij Enter aby wr√≥ciƒá do menu...{Colors.ENDC}")

def semantic_search_demo():
    """Demonstracja wyszukiwania semantycznego z przyk≈Çadami."""
    print_header("DEMONSTRACJA WYSZUKIWANIA SEMANTYCZNEGO")

    demo_queries = [
        "Kr√≥l przyby≈Ç do miasta",
        "Wojna miƒôdzy narodami",
        "Piƒôkna dziewczyna ta≈Ñczy",
        "Jestem bardzo g≈Çodny",
        "Pogoda jest wspania≈Ça"
    ]

    print(f"\n{Colors.BOLD}Przetestujƒô {len(demo_queries)} przyk≈Çadowych zapyta≈Ñ:{Colors.ENDC}\n")

    for i, query in enumerate(demo_queries, 1):
        print(f"\n{Colors.BOLD}{Colors.YELLOW}‚ïê‚ïê‚ïê Query {i}/{len(demo_queries)} ‚ïê‚ïê‚ïê{Colors.ENDC}")

        tokens, vector, similar = find_similar(query, topn=5)
        display_similar_results(query, tokens, similar[:5])

        if i < len(demo_queries):
            input(f"\n{Colors.CYAN}Naci≈õnij Enter aby kontynuowaƒá...{Colors.ENDC}")

# --- Menu g≈Ç√≥wne ---

def main_menu():
    """Wy≈õwietla menu g≈Ç√≥wne i obs≈Çuguje wyb√≥r u≈ºytkownika."""
    while True:
        print_header("MENU G≈Å√ìWNE")
        print(f"\n{Colors.BOLD}Wybierz opcjƒô:{Colors.ENDC}")
        print(f"  {Colors.CYAN}1.{Colors.ENDC} Interaktywne wyszukiwanie (wprowad≈∫ w≈Çasne zdania)")
        print(f"  {Colors.CYAN}2.{Colors.ENDC} Losowe przyk≈Çady z korpusu")
        print(f"  {Colors.CYAN}3.{Colors.ENDC} Demonstracja wyszukiwania semantycznego")
        print(f"  {Colors.CYAN}4.{Colors.ENDC} Wizualizacja embedding√≥w (t-SNE/PCA)")
        print(f"  {Colors.CYAN}5.{Colors.ENDC} Statystyki modelu")
        print(f"  {Colors.CYAN}q.{Colors.ENDC} Zako≈Ñcz")

        try:
            choice = input(f"\n{Colors.BOLD}{Colors.GREEN}Wyb√≥r > {Colors.ENDC}").strip().lower()

            if choice == '1':
                interactive_search()
            elif choice == '2':
                random_examples()
            elif choice == '3':
                semantic_search_demo()
            elif choice == '4':
                visualize_embeddings()
            elif choice == '5':
                show_statistics()
            elif choice in ['q', 'quit', 'exit']:
                print(f"\n{Colors.GREEN}Do widzenia!{Colors.ENDC}\n")
                break
            else:
                print_error("Nieprawid≈Çowy wyb√≥r. Spr√≥buj ponownie.")

        except EOFError:
            print(f"\n{Colors.YELLOW}Zako≈Ñczono.{Colors.ENDC}")
            break
        except KeyboardInterrupt:
            print(f"\n\n{Colors.YELLOW}Przerwano przez u≈ºytkownika.{Colors.ENDC}")
            break

# --- Uruchomienie programu ---

if __name__ == "__main__":
    try:
        main_menu()
    except Exception as e:
        print_error(f"Nieoczekiwany b≈ÇƒÖd: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
